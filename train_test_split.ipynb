{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The goal of this file is to import all of the training samples, and split them into \n",
    "training, testing, and validation sets with an 80:10:10 split. \n",
    "\n",
    "We export these because we want them to be consistent across all training and testing\n",
    "\n",
    "We create a validation + test set for cases where we want the most training possible\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import all samples\n",
    "'''\n",
    "all_samples = pd.read_csv('data/flickr_8k/captions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get the filenames for the training, validation, and test sets\n",
    "\n",
    "split the train/val/test 80/10/10\n",
    "'''\n",
    "# get all of the filenames from the dataset \n",
    "ALL_FILENAMES = list(set(all_samples['image']))\n",
    "# split the filenames into train test val 80-10-10\n",
    "TRAIN_FILENAMES, TEST_FILENAMES = train_test_split(ALL_FILENAMES, test_size=0.2, random_state=RANDOM_SEED)\n",
    "TEST_FILENAMES, VALIDATION_FILENAMES = train_test_split(TEST_FILENAMES, test_size=0.5, random_state=RANDOM_SEED) \n",
    "# define a combined training plus validatoin set\n",
    "TRAIN_AND_VAL_FILENAMES = TRAIN_FILENAMES + VALIDATION_FILENAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "get the actual rows from the df corresponding to the different sets\n",
    "'''\n",
    "# get the samples with the given filenames\n",
    "train_samples = all_samples.loc[all_samples['image'].isin(TRAIN_FILENAMES)]\n",
    "validation_samples = all_samples.loc[all_samples['image'].isin(VALIDATION_FILENAMES)]\n",
    "test_samples = all_samples.loc[all_samples['image'].isin(TEST_FILENAMES)]\n",
    "train_and_val_samples = all_samples.loc[all_samples['image'].isin(TRAIN_AND_VAL_FILENAMES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "export these to files so that they can be consistent no matter what\n",
    "\n",
    "commented out and removed so that this is not run again\n",
    "'''\n",
    "# train_samples.to_csv('data/flickr_8k/train.csv', index=False)\n",
    "# validation_samples.to_csv('data/flickr_8k/validation.csv', index=False)\n",
    "# test_samples.to_csv('data/flickr_8k/test.csv', index=False)\n",
    "# train_and_val_samples.to_csv('data/flickr_8k/train_and_val.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0184f448d6494873b5885b7cafa76c11f0e318a0940098d9222ca8536d4b3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
