{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import clean_descriptions\n",
    "from common import samples_to_dict, max_and_average_sequence_length, get_tokenizer_from_samples\n",
    "from LogisticDecoder import LogisticDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the cleaned data and print one example\n",
    "cleaned_data = clean_descriptions('../data/flickr_8k/captions.txt')\n",
    "print(cleaned_data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "get the actual rows from the df corresponding to the different sets\n",
    "'''\n",
    "# get the samples with the given filenames\n",
    "train_samples = clean_descriptions('../data/flickr_8k/train.csv')\n",
    "validation_samples = clean_descriptions('../data/flickr_8k/validation.csv')\n",
    "test_samples = clean_descriptions('../data/flickr_8k/test.csv')\n",
    "train_and_val_samples = clean_descriptions('../data/flickr_8k/train_and_val.csv')\n",
    "small_train_samples = clean_descriptions('../data/flickr_8k/small_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dict = samples_to_dict(train_samples)\n",
    "validation_dict = samples_to_dict(validation_samples)\n",
    "train_and_val_dict = samples_to_dict(train_and_val_samples)\n",
    "test_dict = samples_to_dict(test_samples)\n",
    "small_train_dict = samples_to_dict(small_train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH, AVG_LENGTH = max_and_average_sequence_length(train_and_val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create a logistic decoder model that will be generated for comparing our model types\n",
    "\n",
    "we will compare these against each other in a separate file (model_tuning.ipynb)\n",
    "\n",
    "using the small training set for this comparison\n",
    "'''\n",
    "basic_decoder = LogisticDecoder(12, get_tokenizer_from_samples(small_train_samples))\n",
    "basic_decoder.fit(small_train_samples, 5, '../models/compare_3_models/logistic_model', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "we choose 12 as our max caption length, despite there being many longer captions,\n",
    "computationally we were limited on time, and therefore chose to decrease the number of decoders\n",
    "to the average caption length rather than the maximum seen caption length\n",
    "'''\n",
    "# logistic_decoder = LogisticDecoder(12, get_tokenizer_from_samples(train_and_val_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_decoder.load('LogisticDecoders/train_val_20_epoch_maxlen_12')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0184f448d6494873b5885b7cafa76c11f0e318a0940098d9222ca8536d4b3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
