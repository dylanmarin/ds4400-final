{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file shows an example of how to create, train, load, and generate captions with our \n",
    "logistic decoder class\n",
    "\n",
    "previously it stored all of the code for the class but we extracted it to LogisticDecoder.py for use in other files\n",
    "\n",
    "'''\n",
    "from common import samples_to_dict, get_tokenizer_from_samples, clean_descriptions, VALIDATION_FILENAMES\n",
    "from LogisticDecoder import LogisticDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the cleaned data and print one example\n",
    "cleaned_data = clean_descriptions('../data/flickr_8k/captions.txt')\n",
    "print(cleaned_data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "get the actual rows from the df corresponding to the different sets\n",
    "'''\n",
    "train_samples = clean_descriptions('../data/flickr_8k/train.csv')\n",
    "validation_samples = clean_descriptions('../data/flickr_8k/validation.csv')\n",
    "test_samples = clean_descriptions('../data/flickr_8k/test.csv')\n",
    "train_and_val_samples = clean_descriptions('../data/flickr_8k/train_and_val.csv')\n",
    "small_train_samples = clean_descriptions('../data/flickr_8k/small_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get the samples as dictionaries from image filename to cleaned captions\n",
    "'''\n",
    "training_dict = samples_to_dict(train_samples)\n",
    "validation_dict = samples_to_dict(validation_samples)\n",
    "train_and_val_dict = samples_to_dict(train_and_val_samples)\n",
    "test_dict = samples_to_dict(test_samples)\n",
    "small_train_dict = samples_to_dict(small_train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "example of how to create, train, and load a logistic decoder model \n",
    "\n",
    "we will compare these against each other in a separate file (model_tuning.ipynb)\n",
    "\n",
    "using the small training set for this comparison\n",
    "'''\n",
    "basic_decoder = LogisticDecoder(caption_max_length=15, tokenizer=get_tokenizer_from_samples(small_train_samples))\n",
    "# basic_decoder.fit(small_train_samples, 5, '../models/example/logistic_model', verbose=True)\n",
    "basic_decoder.load('../models/example/logistic_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "note that this only works because we have the extracted features in a pkl file in the data/flickr_8k directory\n",
    "'''\n",
    "basic_decoder.generate_caption(image_filename='387974450_bcd205daac', verbose=True)\n",
    "basic_decoder.generate_captions_for_files(filenames=VALIDATION_FILENAMES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0184f448d6494873b5885b7cafa76c11f0e318a0940098d9222ca8536d4b3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
