{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LogisticDecoder import LogisticDecoder\n",
    "from common import clean_descriptions, samples_to_dict, VALIDATION_FILENAMES, corpus_bleu_score\n",
    "from RNNDecoder import RNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "get the actual rows from the df corresponding to the different sets\n",
    "'''\n",
    "# get the samples with the given filenames\n",
    "small_train_samples = clean_descriptions('../data/flickr_8k/small_train.csv')\n",
    "validation_samples = clean_descriptions('../data/flickr_8k/validation.csv')\n",
    "\n",
    "# NOTE uncomment as needed\n",
    "# train_samples = clean_descriptions('../data/flickr_8k/train.csv')\n",
    "# test_samples = clean_descriptions('../data/flickr_8k/test.csv')\n",
    "# train_and_val_samples = clean_descriptions('../data/flickr_8k/train_and_val.csv')\n",
    "\n",
    "\n",
    "small_train_dict = samples_to_dict(small_train_samples)\n",
    "validation_dict = samples_to_dict(validation_samples)\n",
    "val_captions = list(validation_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create logistic regression model\n",
    "get bleu score on validation set\n",
    "'''\n",
    "logistic_decoder = LogisticDecoder(15, small_train_samples)\n",
    "# logistic_decoder.fit(small_train_dict, 5, '../models/compare_3_models/LogisticModel',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../models/compare_3_models/LogisticModel\n"
     ]
    }
   ],
   "source": [
    "logistic_decoder.load('../models/compare_3_models/LogisticModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_captions = logistic_decoder.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.29785561917592907\n",
      "BLEU-2: 0.07837888206846033\n",
      "BLEU-3: 0.01807101168302499\n",
      "BLEU-4: 6.019673799174596e-79\n"
     ]
    }
   ],
   "source": [
    "logistic_bleu_scores = corpus_bleu_score(val_captions, logistic_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 34, 33, 33, 33, 33, 32, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 29, 28, 28, 28, 28]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      "16180/16180 [==============================] - 368s 23ms/step - loss: 3.3876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x128b82735c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "load RNN without dropout\n",
    "\n",
    "get bleu score on validation set\n",
    "'''\n",
    "rnn_without_dropout_model = RNNModel(False, small_train_samples)\n",
    "rnn_without_dropout_model.train_save_model(input_dict=small_train_dict, save_path='../models/compare_3_models/RNN_without_dropout', epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_without_dropout_model.load('../models/compare_3_models/RNN_without_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_dropout_captions = rnn_without_dropout_model.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.3256668642560759\n",
      "BLEU-2: 0.12261347302117036\n",
      "BLEU-3: 0.03905333234637138\n",
      "BLEU-4: 0.009979650225174266\n"
     ]
    }
   ],
   "source": [
    "without_dropout_bleu_scores = corpus_bleu_score(val_captions, without_dropout_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 34, 33, 33, 33, 33, 32, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 29, 28, 28, 28, 28]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "load RNN with dropout layers\n",
    "\n",
    "get bleu score on validation set\n",
    "'''\n",
    "rnn_with_dropout_model = RNNModel(True, small_train_samples)\n",
    "# rnn_with_dropout_model.train_save_model(input_dict=small_train_dict, save_path='../models/compare_3_models/RNN_with_dropout', epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "rnn_with_dropout_model.load('../models/compare_3_models/RNN_with_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_dropout_captions = rnn_with_dropout_model.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.330918147854636\n",
      "BLEU-2: 0.12436767922869052\n",
      "BLEU-3: 0.04006884227079066\n",
      "BLEU-4: 0.011906023055355095\n"
     ]
    }
   ],
   "source": [
    "with_dropout_bleu_scores = corpus_bleu_score(val_captions, with_dropout_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Note:\n",
    "\n",
    "best model was the model with dropout layers\n",
    "\n",
    "now do hyperparameter tuning on best model\n",
    "'''\n",
    "\n",
    "adam_5_epochs = RNNModel(True, small_train_samples, optimizer='adam')\n",
    "adam_5_epochs.train_save_model(input_dict=small_train_dict, save_path='../models/hyperparameter_tuning/rnn_5_epochs_adam', epochs=5)\n",
    "# adam_5_epochs.load('../models/hyperparameter_tuning/rnn_5_epochs_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_5_captions = adam_5_epochs.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_5_bleu_scores = corpus_bleu_score(val_captions, adam_5_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_10_epochs = RNNModel(True, small_train_samples, optimizer='adam')\n",
    "adam_10_epochs.train_save_model(input_dict=small_train_dict, save_path='../models/hyperparameter_tuning/rnn_10_epochs_adam', epochs=10)\n",
    "# adam_10_epochs.load('../models/hyperparameter_tuning/rnn_10_epochs_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_10_captions = adam_10_epochs.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_10_bleu_scores = corpus_bleu_score(val_captions, adam_10_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_5_epochs = RNNModel(True, small_train_samples, optimizer='sgd')\n",
    "sgd_5_epochs.train_save_model(input_dict=small_train_dict, save_path='../models/hyperparameter_tuning/rnn_5_epochs_sgd', epochs=5)\n",
    "# sgd_5_epochs.load('../models/hyperparameter_tuning/rnn_5_epochs_sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_5_captions = sgd_5_epochs.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_5_bleu_scores = corpus_bleu_score(val_captions, sgd_5_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_10_epochs = RNNModel(True, small_train_samples, optimizer='sgd')\n",
    "sgd_10_epochs.train_save_model(input_dict=small_train_dict, save_path='../models/hyperparameter_tuning/rnn_10_epochs_sgd', epochs=10)\n",
    "# sgd_10_epochs.load('../models/hyperparameter_tuning/rnn_10_epochs_sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_10_captions = sgd_10_epochs.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_10_bleu_scores = corpus_bleu_score(val_captions, sgd_10_captions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0184f448d6494873b5885b7cafa76c11f0e318a0940098d9222ca8536d4b3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
