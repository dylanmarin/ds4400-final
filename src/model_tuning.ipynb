{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LogisticDecoder import LogisticDecoder\n",
    "from common import clean_descriptions, samples_to_dict\n",
    "from RNNDecoder import RNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "get the actual rows from the df corresponding to the different sets\n",
    "'''\n",
    "# get the samples with the given filenames\n",
    "small_train_samples = clean_descriptions('../data/flickr_8k/small_train.csv')\n",
    "validation_samples = clean_descriptions('../data/flickr_8k/validation.csv')\n",
    "\n",
    "# NOTE uncomment as needed\n",
    "# train_samples = clean_descriptions('../data/flickr_8k/train.csv')\n",
    "# test_samples = clean_descriptions('../data/flickr_8k/test.csv')\n",
    "# train_and_val_samples = clean_descriptions('../data/flickr_8k/train_and_val.csv')\n",
    "\n",
    "\n",
    "small_train_dict = samples_to_dict(small_train_samples)\n",
    "validation_dict = samples_to_dict(validation_samples)\n",
    "val_captions = list(validation_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model #1\n",
      "16180/16180 [==============================] - 103s 6ms/step - loss: 128.0771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_1_layer_call_fn, re_lu_1_layer_call_and_return_conditional_losses, re_lu_1_layer_call_fn, re_lu_1_layer_call_and_return_conditional_losses, re_lu_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "create logistic regression model\n",
    "get bleu score on validation set\n",
    "'''\n",
    "logistic_decoder = LogisticDecoder(15, small_train_samples)\n",
    "logistic_decoder.fit(small_train_dict, 5, '../models/compare_3_models/LogisticModel',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnn_without_dropout_model = RNNModel(False, small_train_samples)\n",
    "rnn_without_dropout_model.train_save_model(input_dict=small_train_dict, save_path='../models/compare_3_models/RNN_no_dropout', epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "load RNN without dropout\n",
    "\n",
    "get bleu score on validation set\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "load RNN with dropout layers\n",
    "\n",
    "get bleu score on validation set\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Note:\n",
    "\n",
    "best model was ______\n",
    "\n",
    "now do hyperparameter tuning on best model\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0184f448d6494873b5885b7cafa76c11f0e318a0940098d9222ca8536d4b3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
