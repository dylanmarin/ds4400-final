{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In this file we train many models and evaluate their caption predictions on the validation and test sets\n",
    "\n",
    "This file will also be used to generate some captions for the report\n",
    "\n",
    "All data gathered is in the report\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from LogisticDecoder import LogisticDecoder\n",
    "from common import clean_descriptions, samples_to_dict, VALIDATION_FILENAMES, corpus_bleu_score, TEST_FILENAMES\n",
    "from RNNDecoder import RNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Initialize the samples and dictionaries that will be used in training\n",
    "\n",
    "'''\n",
    "# get the samples with the given filenames\n",
    "small_train_samples = clean_descriptions('../data/flickr_8k/small_train.csv')\n",
    "validation_samples = clean_descriptions('../data/flickr_8k/validation.csv')\n",
    "train_samples = clean_descriptions('../data/flickr_8k/train.csv')\n",
    "test_samples = clean_descriptions('../data/flickr_8k/test.csv')\n",
    "train_and_val_samples = clean_descriptions('../data/flickr_8k/train_and_val.csv')\n",
    "\n",
    "\n",
    "small_train_dict = samples_to_dict(small_train_samples)\n",
    "train_dict = samples_to_dict(train_samples)\n",
    "test_dict = samples_to_dict(test_samples)\n",
    "train_and_val_dict = samples_to_dict(train_and_val_samples)\n",
    "validation_dict = samples_to_dict(validation_samples)\n",
    "\n",
    "# get the captions for the validation set and the test set\n",
    "val_captions = list(validation_dict.values())\n",
    "test_captions = list(test_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../models/compare_3_models/LogisticModel\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following 3 models are used to select which model is best. We will then tune hyper parameters using that model structure\n",
    "\n",
    "create logistic regression model\n",
    "5 epochs\n",
    "small training set\n",
    "evaluate on validation set\n",
    "'''\n",
    "logistic_decoder = LogisticDecoder(15, small_train_samples)\n",
    "# logistic_decoder.fit(small_train_dict, 5, '../models/compare_3_models/LogisticModel',verbose=True)\n",
    "logistic_decoder.load('../models/compare_3_models/LogisticModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.29785561917592907\n",
      "BLEU-2: 0.07837888206846033\n",
      "BLEU-3: 0.01807101168302499\n",
      "BLEU-4: 6.019673799174596e-79\n"
     ]
    }
   ],
   "source": [
    "logistic_captions = logistic_decoder.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)\n",
    "logistic_bleu_scores = corpus_bleu_score(val_captions, logistic_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 34, 33, 33, 33, 33, 32, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 29, 28, 28, 28, 28]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      "16180/16180 [==============================] - 368s 23ms/step - loss: 3.3876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x128b82735c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "create RNN model without dropout layers\n",
    "5 epochs\n",
    "small training set\n",
    "evaluate on validation set\n",
    "'''\n",
    "rnn_without_dropout_model = RNNModel(False, small_train_samples)\n",
    "# rnn_without_dropout_model.train_save_model(input_dict=small_train_dict, save_path='../models/compare_3_models/RNN_without_dropout', epochs=5)\n",
    "rnn_without_dropout_model.load('../models/compare_3_models/RNN_without_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.3256668642560759\n",
      "BLEU-2: 0.12261347302117036\n",
      "BLEU-3: 0.03905333234637138\n",
      "BLEU-4: 0.009979650225174266\n"
     ]
    }
   ],
   "source": [
    "without_dropout_captions = rnn_without_dropout_model.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)\n",
    "without_dropout_bleu_scores = corpus_bleu_score(val_captions, without_dropout_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "create RNN model with dropout layers\n",
    "5 epochs\n",
    "small training set\n",
    "evaluate on validation set\n",
    "'''\n",
    "rnn_with_dropout_model = RNNModel(True, small_train_samples)\n",
    "# rnn_with_dropout_model.train_save_model(input_dict=small_train_dict, save_path='../models/compare_3_models/RNN_with_dropout', epochs=5)\n",
    "rnn_with_dropout_model.load('../models/compare_3_models/RNN_with_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.330918147854636\n",
      "BLEU-2: 0.12436767922869052\n",
      "BLEU-3: 0.04006884227079066\n",
      "BLEU-4: 0.011906023055355095\n"
     ]
    }
   ],
   "source": [
    "with_dropout_captions = rnn_with_dropout_model.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)\n",
    "with_dropout_bleu_scores = corpus_bleu_score(val_captions, with_dropout_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 34, 33, 33, 33, 33, 32, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 29, 28, 28, 28, 28]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      "16180/16180 [==============================] - 325s 20ms/step - loss: 3.4480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x2632f1b8bc8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Note:\n",
    "\n",
    "best model was the RNN model with dropout layers\n",
    "\n",
    "now do hyperparameter tuning on best model\n",
    "\n",
    "optimizer   | # epochs\n",
    "adam        | 5\n",
    "adam        | 10\n",
    "sgd         | 5\n",
    "sgd         | 10\n",
    "\n",
    "\n",
    "evaluate each model on the validation set\n",
    "'''\n",
    "adam_5_epochs = RNNModel(True, small_train_samples, optimizer='adam')\n",
    "# adam_5_epochs.train_save_model(input_dict=small_train_dict, save_path='../models/hyperparameter_tuning/rnn_5_epochs_adam', epochs=5)\n",
    "adam_5_epochs.load('../models/hyperparameter_tuning/rnn_5_epochs_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.3141850995928249\n",
      "BLEU-2: 0.12398919098008251\n",
      "BLEU-3: 0.044220494743823155\n",
      "BLEU-4: 0.015097778742097986\n"
     ]
    }
   ],
   "source": [
    "adam_5_captions = adam_5_epochs.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)\n",
    "adam_5_bleu_scores = corpus_bleu_score(val_captions, adam_5_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 34, 33, 33, 33, 33, 32, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 29, 28, 28, 28, 28]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      "32360/32360 [==============================] - 665s 20ms/step - loss: 3.0602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x1d33cef2bc8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "RNN model with dropout \n",
    "adam optimizer 10 epochs\n",
    "'''\n",
    "adam_10_epochs = RNNModel(True, small_train_samples, optimizer='adam')\n",
    "# adam_10_epochs.train_save_model(input_dict=small_train_dict, save_path='../models/hyperparameter_tuning/rnn_10_epochs_adam', epochs=10)\n",
    "adam_10_epochs.load('../models/hyperparameter_tuning/rnn_10_epochs_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.32845714285714284\n",
      "BLEU-2: 0.1268539236921717\n",
      "BLEU-3: 0.04595459169877701\n",
      "BLEU-4: 0.016645342560671805\n"
     ]
    }
   ],
   "source": [
    "adam_10_captions = adam_10_epochs.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)\n",
    "adam_10_bleu_scores = corpus_bleu_score(val_captions, adam_10_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 34, 33, 33, 33, 33, 32, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 29, 28, 28, 28, 28]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      "16180/16180 [==============================] - 306s 19ms/step - loss: 5.1198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x1d5305f4f08>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "RNN model with dropout \n",
    "sgd optimizer 5 epochs\n",
    "'''\n",
    "sgd_5_epochs = RNNModel(True, small_train_samples, optimizer='sgd')\n",
    "# sgd_5_epochs.train_save_model(input_dict=small_train_dict, save_path='../models/hyperparameter_tuning/rnn_5_epochs_sgd', epochs=5)\n",
    "sgd_5_epochs.load('../models/hyperparameter_tuning/rnn_5_epochs_sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.21240199572344975\n",
      "BLEU-2: 0.04881005024237703\n",
      "BLEU-3: 0.006275917064585577\n",
      "BLEU-4: 2.723290711024397e-79\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "RNN model with dropout \n",
    "sgd optimizer 5 epochs\n",
    "'''\n",
    "sgd_5_captions = sgd_5_epochs.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)\n",
    "sgd_5_bleu_scores = corpus_bleu_score(val_captions, sgd_5_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 34, 33, 33, 33, 33, 32, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 29, 28, 28, 28, 28]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      "32360/32360 [==============================] - 605s 19ms/step - loss: 4.8537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x1d562882088>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "RNN model with dropout \n",
    "sgd optimizer 10 epochs\n",
    "'''\n",
    "sgd_10_epochs = RNNModel(True, small_train_samples, optimizer='sgd')\n",
    "# sgd_10_epochs.train_save_model(input_dict=small_train_dict, save_path='../models/hyperparameter_tuning/rnn_10_epochs_sgd', epochs=10)\n",
    "sgd_10_epochs.load('../models/hyperparameter_tuning/rnn_10_epochs_sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.23887316875615988\n",
      "BLEU-2: 0.059317915316757834\n",
      "BLEU-3: 4.089993830033175e-104\n",
      "BLEU-4: 3.3961826536174215e-155\n"
     ]
    }
   ],
   "source": [
    "sgd_10_captions = sgd_10_epochs.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)\n",
    "sgd_10_bleu_scores = corpus_bleu_score(val_captions, sgd_10_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 34, 33, 33, 33, 33, 33, 32, 32, 32, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      "64720/64720 [==============================] - 1902s 29ms/step - loss: 3.0960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x1c337cca948>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The next 3 models are ALL THREE models trained with the best hyperparameters\n",
    "\n",
    "adam optimizer with 10 epochs\n",
    "\n",
    "First the RNN model with dropout layers\n",
    "Second the RNN model without dropout layers\n",
    "Lastly the Logistic Decoder model\n",
    "\n",
    "All will be tested on the validation set again\n",
    "'''\n",
    "full_train_10_epochs = RNNModel(True, train_samples, optimizer='adam')\n",
    "# full_train_10_epochs.train_save_model(input_dict=train_dict, save_path='../models/full_training_data/rnn_10_epochs_adam', epochs=10)\n",
    "full_train_10_epochs.load('../models/full_training_data/rnn_10_epochs_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.3318903318903319\n",
      "BLEU-2: 0.1377854245892623\n",
      "BLEU-3: 0.05011937620648899\n",
      "BLEU-4: 0.018407808337102996\n"
     ]
    }
   ],
   "source": [
    "full_train_10_captions = full_train_10_epochs.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)\n",
    "full_train_10_bleu_scores = corpus_bleu_score(val_captions, full_train_10_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 34, 33, 33, 33, 33, 33, 32, 32, 32, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      "64720/64720 [==============================] - 1614s 25ms/step - loss: 2.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x223964bbbc8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "RNN model without dropout\n",
    "'''\n",
    "full_train_without_dropout_10_epochs = RNNModel(False, train_samples, optimizer='adam')\n",
    "# full_train_without_dropout_10_epochs.train_save_model(input_dict=train_dict, save_path='../models/full_training_data/no_dropout_10_epochs_adam', epochs=10)\n",
    "full_train_without_dropout_10_epochs.load('../models/full_training_data/no_dropout_10_epochs_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.31642430391162213\n",
      "BLEU-2: 0.11737997545158703\n",
      "BLEU-3: 0.03715791149037828\n",
      "BLEU-4: 0.013360267231810248\n"
     ]
    }
   ],
   "source": [
    "full_train_without_dropout_10_captions = full_train_without_dropout_10_epochs.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)\n",
    "full_train_without_dropout_10_bleu_scores = corpus_bleu_score(val_captions, full_train_without_dropout_10_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model #1\n",
      "64720/64720 [==============================] - 494s 8ms/step - loss: 194.4171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #1 saved to ../models/full_training_data/logistic_model/decoder1\n",
      "Training model #2\n",
      "64720/64720 [==============================] - 495s 8ms/step - loss: 401.1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #2 saved to ../models/full_training_data/logistic_model/decoder2\n",
      "Training model #3\n",
      "64720/64720 [==============================] - 504s 8ms/step - loss: 479.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #3 saved to ../models/full_training_data/logistic_model/decoder3\n",
      "Training model #4\n",
      "64720/64720 [==============================] - 493s 8ms/step - loss: 511.1817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #4 saved to ../models/full_training_data/logistic_model/decoder4\n",
      "Training model #5\n",
      "64720/64720 [==============================] - 495s 8ms/step - loss: 559.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #5 saved to ../models/full_training_data/logistic_model/decoder5\n",
      "Training model #6\n",
      "64720/64720 [==============================] - 498s 8ms/step - loss: 620.8386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #6 saved to ../models/full_training_data/logistic_model/decoder6\n",
      "Training model #7\n",
      "64720/64720 [==============================] - 494s 8ms/step - loss: 628.4890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #7 saved to ../models/full_training_data/logistic_model/decoder7\n",
      "Training model #8\n",
      "64720/64720 [==============================] - 493s 8ms/step - loss: 665.6412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #8 saved to ../models/full_training_data/logistic_model/decoder8\n",
      "Training model #9\n",
      "64610/64610 [==============================] - 492s 8ms/step - loss: 736.7569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #9 saved to ../models/full_training_data/logistic_model/decoder9\n",
      "Training model #10\n",
      "63980/63980 [==============================] - 490s 8ms/step - loss: 822.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #10 saved to ../models/full_training_data/logistic_model/decoder10\n",
      "Training model #11\n",
      "62530/62530 [==============================] - 483s 8ms/step - loss: 905.1826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder11\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #11 saved to ../models/full_training_data/logistic_model/decoder11\n",
      "Training model #12\n",
      "59880/59880 [==============================] - 461s 8ms/step - loss: 1014.1894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder12\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #12 saved to ../models/full_training_data/logistic_model/decoder12\n",
      "Training model #13\n",
      "55600/55600 [==============================] - 428s 8ms/step - loss: 1100.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder13\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder13\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #13 saved to ../models/full_training_data/logistic_model/decoder13\n",
      "Training model #14\n",
      "49540/49540 [==============================] - 372s 8ms/step - loss: 1172.5592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder14\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder14\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #14 saved to ../models/full_training_data/logistic_model/decoder14\n",
      "Training model #15\n",
      "41730/41730 [==============================] - 314s 8ms/step - loss: 1201.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder15\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/full_training_data/logistic_model/decoder15\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collected.\n",
      "Model #15 saved to ../models/full_training_data/logistic_model/decoder15\n",
      "Model loaded from ../models/full_training_data/logistic_model\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "logistic model trained on training set\n",
    "'''\n",
    "full_train_logistic_decoder = LogisticDecoder(15, train_samples)\n",
    "# full_train_logistic_decoder.fit(train_dict, 10, '../models/full_training_data/logistic_model',verbose=True)\n",
    "full_train_logistic_decoder.load('../models/full_training_data/logistic_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 18669 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001897AAAEC18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 18669 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001897AAAEC18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 18670 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001897AAEB558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 18670 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001897AAEB558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.31083639603519325\n",
      "BLEU-2: 0.0852507420770845\n",
      "BLEU-3: 0.019049863044182973\n",
      "BLEU-4: 0.005696527662864323\n"
     ]
    }
   ],
   "source": [
    "full_train_logistic_captions = full_train_logistic_decoder.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)\n",
    "full_train_logistic_bleu_scores = corpus_bleu_score(val_captions, full_train_logistic_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 35, 34, 33, 33, 33, 33, 33, 32, 32, 32, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 30]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      "model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "train all 3 model types on full training + validation set with best hyper parameters\n",
    "\n",
    "use these just for testing some caption generation\n",
    "'''\n",
    "\n",
    "full_train_val_rnn_10_epochs = RNNModel(True, train_and_val_samples, optimizer='adam')\n",
    "# full_train_val_rnn_10_epochs.train_save_model(input_dict=train_and_val_dict, save_path='../models/full_training_val_data/rnn_10_epochs_adam', epochs=10)\n",
    "full_train_val_rnn_10_epochs.load('../models/full_training_val_data/rnn_10_epochs_adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.3113781939020562\n",
      "BLEU-2: 0.10670162658613169\n",
      "BLEU-3: 0.033282317301041336\n",
      "BLEU-4: 0.010834366325297313\n"
     ]
    }
   ],
   "source": [
    "full_train_val_rnn_10_captions = full_train_val_rnn_10_epochs.generate_captions_for_files(TEST_FILENAMES, verbose=False)\n",
    "full_train_val_10_bleu_scores = corpus_bleu_score(test_captions, full_train_val_rnn_10_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 35, 34, 33, 33, 33, 33, 33, 32, 32, 32, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 30]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      "model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "RNN model without dropout on training + validation set\n",
    "'''\n",
    "full_train_val_without_dropout_10_epochs = RNNModel(False, train_and_val_samples, optimizer='adam')\n",
    "# full_train_val_without_dropout_10_epochs.train_save_model(input_dict=train_and_val_dict, save_path='../models/full_training_val_data/no_dropout_10_epochs_adam', epochs=10)\n",
    "full_train_val_without_dropout_10_epochs.load('../models/full_training_val_data/no_dropout_10_epochs_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.31462000858737654\n",
      "BLEU-2: 0.12268801995467031\n",
      "BLEU-3: 0.04204070609542318\n",
      "BLEU-4: 0.013412006916045766\n"
     ]
    }
   ],
   "source": [
    "full_train_val_without_dropout_10_captions = full_train_val_without_dropout_10_epochs.generate_captions_for_files(TEST_FILENAMES, verbose=False)\n",
    "full_train_val_without_dropout_10_bleu_scores = corpus_bleu_score(test_captions, full_train_val_without_dropout_10_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../models/full_training_val_data/logistic_model\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "logistic model trained on training + validation set\n",
    "'''\n",
    "full_train_val_logistic_decoder = LogisticDecoder(15, train_and_val_samples)\n",
    "# full_train_val_logistic_decoder.fit(train_and_val_dict, 10, '../models/full_training_val_data/logistic_model',verbose=True)\n",
    "full_train_val_logistic_decoder.load('../models/full_training_val_data/logistic_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002278B2C5F78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002278B4BF558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "BLEU-1: 0.3000620604054613\n",
      "BLEU-2: 0.07453068567495304\n",
      "BLEU-3: 0.019038151757266815\n",
      "BLEU-4: 0.0055555105652504615\n"
     ]
    }
   ],
   "source": [
    "full_train_val_logistic_captions = full_train_val_logistic_decoder.generate_captions_for_files(TEST_FILENAMES, verbose=False)\n",
    "full_train_val_logistic_bleu_scores = corpus_bleu_score(test_captions, full_train_val_logistic_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "combine and export all captions generated by our 3 fully trained models for viewing\n",
    "'''\n",
    "def concat_string(tokens):\n",
    "    output = ''\n",
    "    for i, tok in enumerate(tokens):\n",
    "        output += tok\n",
    "        if i < len(tokens)-1:\n",
    "            output += ' '\n",
    "    return output\n",
    "\n",
    "def convert_lists(lists_of_toks):\n",
    "    '''\n",
    "    remove <start> and <end> from true labels and reappend them to the list\n",
    "    '''\n",
    "    output = []\n",
    "    for token_list in lists_of_toks:\n",
    "        token_list = token_list[1:len(token_list)-1]\n",
    "        output.append(concat_string(token_list))\n",
    "    return output\n",
    "\n",
    "\n",
    "# commented to not overwrite files\n",
    "# pd.concat([\n",
    "#     pd.Series(test_captions, name='True Captions', index=TEST_FILENAMES).apply(convert_lists),\n",
    "#     pd.Series(full_train_val_rnn_10_captions, name='RNN With Dropout Layers', index=TEST_FILENAMES).apply(concat_string),\n",
    "#     pd.Series(full_train_val_without_dropout_10_captions, name='RNN Without Dropout', index=TEST_FILENAMES).apply(concat_string),\n",
    "#     pd.Series(full_train_val_logistic_captions, name='LogisticDecoder', index=TEST_FILENAMES).apply(concat_string)\n",
    "# ], axis=1).to_csv('../data/generated_captions.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below this cell are just some extra experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 35, 34, 33, 33, 33, 33, 33, 32, 32, 32, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 30]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      " 456572/Unknown - 12182s 27ms/step - loss: 2.8844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11308\\3794315719.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdropout_train_val_50_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNNModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_and_val_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdropout_train_val_50_epochs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_and_val_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../models/full_training_val_data/with_dropout_50_epochs_adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# dropout_train_val_50_epochs.load('../models/full_training_val_data/with_dropout_50_epochs_adam')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\toyso\\Documents\\NEU\\fourth_year\\ds4400-final\\src\\RNNDecoder.py\u001b[0m in \u001b[0;36mtrain_save_model\u001b[1;34m(self, input_dict, save_path, epochs)\u001b[0m\n\u001b[0;32m    154\u001b[0m         '''\n\u001b[0;32m    155\u001b[0m         \u001b[0mcreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpython\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[0mfilename_description_dictionary\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdictoinary\u001b[0m \u001b[0mof\u001b[0m \u001b[0msamples\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfive\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0mto\u001b[0m \u001b[0mloop\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msince\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mtraditionally\u001b[0m \u001b[0mone\u001b[0m \u001b[0muse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3131\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3133\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1960\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    604\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 59\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "train our best model on 150 epochs and evaluate some captions\n",
    "'''\n",
    "dropout_train_val_50_epochs = RNNModel(True, train_and_val_samples, optimizer='adam')\n",
    "# dropout_train_val_50_epochs.train_save_model(input_dict=train_and_val_dict, save_path='../models/full_training_val_data/with_dropout_50_epochs_adam', epochs=50)\n",
    "# dropout_train_val_50_epochs.load('../models/full_training_val_data/with_dropout_50_epochs_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_train_val_50_test_captions = dropout_train_val_50_epochs.generate_captions_for_files(TEST_FILENAMES, verbose=False)\n",
    "dropout_train_val_50_test_bleu_scores = corpus_bleu_score(test_captions, dropout_train_val_50_test_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 sequence lengths are:\n",
      "[35, 35, 34, 33, 33, 33, 33, 33, 32, 32, 32, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n",
      "The longest sequence length from the training and validation samples is 35\n",
      "The average sequence length from the training and validation samples is 12\n",
      "970800/970800 [==============================] - 27884s 29ms/step - loss: 2.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toyso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x189786d4148>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "original goal for this model was to train it overnight on the entire training + validation set\n",
    "accidentally trained it on only training set\n",
    "'''\n",
    "\n",
    "full_train_150_epochs = RNNModel(True, train_samples, optimizer='adam')\n",
    "# full_train_150_epochs.train_save_model(input_dict=train_dict, save_path='../models/full_training_data/with_dropout_150_epochs_adam', epochs=150)\n",
    "full_train_150_epochs.load('../models/full_training_data/with_dropout_150_epochs_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.32126058325493884\n",
      "BLEU-2: 0.1148672362951185\n",
      "BLEU-3: 0.04351843938060441\n",
      "BLEU-4: 0.01755540276109546\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "scores on validation set\n",
    "'''\n",
    "full_train_150_val_captions = full_train_150_epochs.generate_captions_for_files(VALIDATION_FILENAMES, verbose=False)\n",
    "full_train_150_val_bleu_scores = corpus_bleu_score(val_captions, full_train_150_val_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.31631936314680403\n",
      "BLEU-2: 0.11440997030157263\n",
      "BLEU-3: 0.04298068429853824\n",
      "BLEU-4: 0.015962406999144314\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "scores on test set\n",
    "'''\n",
    "full_train_150_test_captions = full_train_150_epochs.generate_captions_for_files(TEST_FILENAMES, verbose=False)\n",
    "full_train_150_test_bleu_scores = corpus_bleu_score(test_captions, full_train_150_test_captions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0184f448d6494873b5885b7cafa76c11f0e318a0940098d9222ca8536d4b3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
